{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# word2vec\n",
    "\n",
    "Автор: Торилов Дмитрий, БПИ173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Дистрибутивная семантика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1 Семантика и Компьютерная лингвистика\n",
    "- Семантика - раздел лингвистики, изучающий смысловое значение единиц языка.\n",
    "- Компьютерная лингвистика – это наука о том, как работать с языком (не всегда естественным), с помощью компьютерных методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Уровни анализа языка\n",
    "Компьютерная лингвистика легко моделирует низлежащие уровни анализа:\n",
    "- Фонетика (какие слова имеют схожее звучание?)\n",
    "- Морфология (какие составные части слова?)\n",
    "- Синтаксис (какие слова выполняют одну и ту же функцию в предложении?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Следующий шаг: **семантика**. Необходимо найти такие **репрезентации** слов, чтобы синонимичные слова имели близкие репрезентации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# **лампа, светильник, кипятильник**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Семантику слов нельзя проанализировать ни фонетически, ни морфологически, ни синтаксически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.3 Где брать данные?\n",
    "Существуют два фундаментальных подхода к определению семантики:\n",
    "- Построение **онтологий** (knowledge-based approach)\n",
    "- Извлечение значений из **употребления слов** (distributional approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.4 Дистрибутивная гипотеза\n",
    "Лингвистические единицы, встречающиеся в схожих контекстах, имеют близкие значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.5 Обучение компьютера семантике\n",
    "- Корпус\n",
    "- Модель, описывающая совместную встречаемость слов в корпусе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Семантические вектора\n",
    "В традиционной дистрибутивной семантике слова описываются векторами, где в качестве измерений (компонентов) выступают соседи этих слов в текстовом корпусе. Количество измерений вектора в **счётной модели** равно количеству слов в корпусе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 2.1 Алгоритм\n",
    "1. Создаём лексикон корпуса N.\n",
    "2. Для каждого слова определяем, какие слова стояли рядом.\n",
    "3. Характеризуем слово вектором, измерения которого определяют, с какими словами и как часто это слово соседствовало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |<big>вектор|<big>значение|<big>хомяк|<big>семантика|<big>суслик|\n",
    "|:----------------:|:---------------:|:------------------:|:-----------------:|:-----------------:|:------------------:|\n",
    "|<big>вектор</big>|0|10|0|8|0|\n",
    "|<big>значение</big>|10|0|1|15|0|\n",
    "|<big>хомяк</big>|0|1|0|0|20|\n",
    "|<big>семантика</big>|8|15|0|0|0|\n",
    "|<big>суслик</big>|0|0|20|0|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 Многомерное векторное пространство\n",
    " Получено **многомерное векторное пространство**\n",
    "1. Слова являются **координатными осями**\n",
    "2. Слова являются **векторами** в этом многомерном пространстве\n",
    "3. Количество измерений равно количеству слов в корпусе\n",
    "4. Векторы **разреженные**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3 В качестве развития\n",
    "Можно использовать не абсолютную частоту совместной встречаемости слов, а как-либо её взвешивать. Коэффициент Дайса:\n",
    "$$ Dice(w,w') = \\frac{2c(w,w')}{c(w)+c(w')}, $$\n",
    "где\n",
    "\n",
    "$c(w)$ - абсолютная частота встречаемости слова $w$,\n",
    "\n",
    "$c(w')$ - абсолютная частота встречаемости слова $w'$,\n",
    "\n",
    "$c(w,w')$ - частота совместной встречаемости слов $w,w'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.4 Матрица совместной встречаемости\n",
    "При создании **матрицы совместной встречаемости** можно смотреть не только на непосредственных соседей, но и на слова, находящиеся в **контекстном окне**.\n",
    "\n",
    "... животных (в том числе и у **[человека) различают головной _мозг_, размещённый в полости черепа]**, и спинной ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Семантическая близость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.1 Косинусная близость\n",
    "Классический способ определения семантической близости слов в векторном пространстве.\n",
    "- Схожесть слов выше по мере уменьшения угла между векторами слов\n",
    "- Схожесть слов выше по мере увеличения косинуса угла между векторами слов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ cos(w, w') = \\frac{(\\overrightarrow{V}(w), \\overrightarrow{V}(w'))}{|\\overrightarrow{V}(w)| \\cdot |\\overrightarrow{V}(w')|}, $$\n",
    "\n",
    "где\n",
    "\n",
    "$w$ и $w'$ - некоторые слова,\n",
    "\n",
    "$\\overrightarrow{V}(a)$ - операция взятия вектора от слова $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Пример с хомяками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |<big>вектор|<big>значение|<big>хомяк|<big>семантика|<big>суслик|\n",
    "|:----------------:|:---------------:|:------------------:|:-----------------:|:-----------------:|:------------------:|\n",
    "|<big>вектор</big>|0|0.78|0|0.625|0|\n",
    "|<big>значение</big>|0.55|0|0.055|0.83|0|\n",
    "|<big>хомяк</big>|0|0.05|0|0|0.99|\n",
    "|<big>семантика</big>|0.47|0.88|0|0|0|\n",
    "|<big>суслик</big>|0|0|1|0|0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector = np.array([0, 0.78, 0, 0.625, 0])\n",
    "value = np.array([0.55, 0, 0.055, 0.83, 0])\n",
    "hamster = np.array([0, 0.05, 0, 0, 0.99])\n",
    "semantics = np.array([0.47, 0.88, 0, 0, 0])\n",
    "gopher = np.array([0, 0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def dist(a, b) -> float:\n",
    "    return (a @ b) / (np.linalg.norm(a) + np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259800945577\n",
      "0.0195903683786\n"
     ]
    }
   ],
   "source": [
    "print(dist(vector, value))\n",
    "print(dist(vector, hamster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Недостатки счётных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Большой размер векторов\n",
    "2. Медленные операции над векторами\n",
    "3. Классические методы снижения размерности (PCA, SVD и т.п.) снижают качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Предсказательные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Мы пытаемся от каждого слова найти такой вектор (embedding), чтобы он был максимально схож с векторами слов-соседей\n",
    "и максимально отличался от остальных слов.\n",
    "- Обычно такой вектор небольшой размерности (порядка сотен компонентов) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В **счётных моделях** $\\overrightarrow{word} = [w_1, w_2, \\dots w_n], $ где $n$ - число слов в корпусе (например, около $10^6$)\n",
    "\n",
    "В **предсказательных моделях** $\\overrightarrow{word} = [w_1, w_2, \\dots w_m], $ где $m$ - заданный при обучении размер (например, около $500$)\n",
    "\n",
    "Репрезентация слов с помощью предсказательных моделей намного эффективнее на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Вероятность встретить два слова вместе: $$\\frac{e^{score(a,b)}}{\\sum_w e^{score(a,w)}}$$\n",
    "Обучение: оптимизация функции потерь.\n",
    "\n",
    "Функция потерь выбирается произвольно (например, перекрёстная энтропия)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. word2vec\n",
    "В 2013 году Tomas Mikolov из Google с соавторами опубликовал статью Efficient Estimation of Word Representations in Vector Space. Чуть позже был выложен код утилиты word2vec, которая позволяет тренировать нейронные языковые модели на больших корпусах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Миколов модифицировал сущестующие алгоритмы: удалил из сети скрытый слой, использовал при обучении иерархический софтмакс. Важно, что word2vec **обучается на порядки быстрее** своих предшественников."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![alt text](pic2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![alt text](pic.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dim\\Anaconda35\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(r'''c:\\Users\\Dim\\Downloads\\araneum_upos_skipgram_300_2_2018.vec''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Обученные модели можно взять http://rusvectores.org/ru/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.027465    0.100439   -0.103324   -0.082207   -0.030868   -0.015183\n",
      "  0.000598   -0.079377   -0.002283    0.063085    0.034348    0.077064\n",
      "  0.11245     0.094937   -0.019655   -0.034419    0.090761    0.092722\n",
      " -0.026385   -0.076239   -0.031656   -0.033933   -0.04341     0.059522\n",
      " -0.028613   -0.017589   -0.063313    0.004186    0.041362   -0.014075\n",
      "  0.027321    0.001999   -0.038185   -0.051985    0.01361     0.032793\n",
      " -0.047974    0.003728   -0.045664   -0.10107     0.022689    0.065924\n",
      "  0.004075    0.02786    -0.061815    0.003811    0.052616   -0.04216\n",
      " -0.028876    0.074481    0.12782501  0.099874    0.056212    0.076138\n",
      " -0.010256    0.102529    0.082981    0.07683     0.118031   -0.0882\n",
      "  0.026836   -0.037248    0.053663   -0.04625    -0.177984   -0.094721\n",
      " -0.069048   -0.042868    0.072968   -0.04379    -0.001721    0.011135\n",
      "  0.004856    0.003208    0.053068   -0.101371    0.016349   -0.036513\n",
      " -0.0768     -0.102599   -0.014578   -0.070232    0.023118    0.009445\n",
      " -0.07049    -0.033713    0.092194    0.017613    0.044862   -0.029089\n",
      " -0.017404   -0.040914    0.052862   -0.122423   -0.017625    0.062039\n",
      "  0.017903    0.003437    0.005758   -0.13166    -0.142593    0.08394\n",
      "  0.008127    0.017807   -0.027269    0.06831     0.067919   -0.038145\n",
      "  0.002945    0.076957   -0.058304    0.066722   -0.047724   -0.016939\n",
      "  0.080225    0.101645   -0.053669    0.022801    0.016384    0.060852\n",
      " -0.023967    0.051224   -0.037627    0.093137    0.011748   -0.039901\n",
      " -0.032285   -0.088936    0.049689   -0.094118   -0.003689   -0.111317\n",
      " -0.050472   -0.028177    0.029722    0.088657   -0.047927   -0.10385\n",
      " -0.063351    0.024215    0.081655    0.06325     0.005489    0.008171\n",
      "  0.03348    -0.002613   -0.038714   -0.000483   -0.09269    -0.098008\n",
      "  0.027138   -0.063201   -0.018795    0.02637    -0.01909     0.051077\n",
      " -0.007039   -0.023653   -0.071282   -0.044262    0.101918    0.073516\n",
      "  0.059058   -0.036858    0.065667   -0.024194   -0.013017    0.009095\n",
      " -0.003193    0.014528    0.072223   -0.079113   -0.007204   -0.010014\n",
      "  0.037054   -0.077781    0.001701    0.127428    0.06864     0.046267\n",
      "  0.022767    0.020422   -0.119982    0.057718    0.007618    0.043954\n",
      " -0.047058    0.020622   -0.079512   -0.000922    0.058139   -0.085288\n",
      " -0.006791    0.000356    0.049111    0.02841    -0.011739   -0.014355\n",
      "  0.037111    0.003932   -0.025847   -0.107603    0.044167    0.13003699\n",
      "  0.046865    0.045239    0.039437   -0.046719    0.022687    0.016318\n",
      "  0.048287   -0.035836    0.027005    0.026948    0.038028    0.124551\n",
      " -0.04271     0.005065    0.003461    0.065785    0.011282   -0.045312\n",
      "  0.018874    0.044355   -0.032067    0.053005   -0.023234   -0.023594\n",
      "  0.04991     0.029049   -0.001399   -0.089729   -0.177118   -0.073952\n",
      "  0.01018    -0.050295   -0.042067   -0.046375    0.013542   -0.062325\n",
      " -0.008358    0.046003   -0.036718   -0.02045     0.03807     0.036636\n",
      "  0.025439    0.047722   -0.074226   -0.021935   -0.044113    0.015005\n",
      " -0.061086   -0.012042   -0.031377    0.022255   -0.080199   -0.013978\n",
      "  0.015993    0.02152    -0.042215    0.054849    0.016947   -0.073227\n",
      "  0.035818   -0.114139   -0.074117    0.102393    0.040847   -0.013154\n",
      "  0.107681    0.025874    0.020927   -0.010557    0.067425   -0.00532\n",
      "  0.016533   -0.067549   -0.035696    0.044142   -0.044438    0.083356\n",
      "  0.003063   -0.067622    0.045468    0.064446   -0.029013   -0.012398\n",
      "  0.03541     0.041902    0.094749    0.053634    0.096908   -0.038786\n",
      "  0.006233    0.01415    -0.000771    0.042422   -0.037947   -0.093653  ]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model['сталь_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model['сталь_NOUN'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39700094968\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.similarity('станок_NOUN', 'цех_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0168052968293\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.similarity('цех_NOUN', 'кошка_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841764280309\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.similarity('собака_NOUN', 'кошка_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "банка_NOUN\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.doesnt_match(['пламя_NOUN', 'ракета_NOUN', 'полёт_NOUN', 'банка_NOUN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "творог_NOUN\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.doesnt_match(['кошка_NOUN', 'собака_NOUN', 'творог_NOUN', 'крокодил_NOUN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "шторм_NOUN 0.7346199154853821\n",
      "ураган_NOUN 0.6847695112228394\n",
      "шквал_NOUN 0.6608145833015442\n",
      "гроза_NOUN 0.6256261467933655\n",
      "бушевать_VERB 0.6216868162155151\n",
      "вихорь_NOUN 0.604590654373169\n",
      "смерч_NOUN 0.5785956382751465\n",
      "ливень_NOUN 0.5740789175033569\n",
      "вьюга_NOUN 0.5724593997001648\n",
      "ненастье_NOUN 0.5642626285552979\n",
      "гром_NOUN 0.5467022061347961\n",
      "метель_NOUN 0.5462476015090942\n",
      "ветер_NOUN 0.541536271572113\n",
      "цунами_NOUN 0.5354753732681274\n",
      "волнение_NOUN 0.5273317694664001\n"
     ]
    }
   ],
   "source": [
    "pairs = w2v_model.most_similar(positive=['буря_NOUN'], topn=15)\n",
    "for word, score in pairs:\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мужчина_NOUN 0.6810499429702759\n"
     ]
    }
   ],
   "source": [
    "vec = w2v_model['королева_NOUN'] - w2v_model['король_NOUN'] + w2v_model['женщина_NOUN']\n",
    "pairs = w2v_model.similar_by_vector(vec, topn=2, restrict_vocab=None)\n",
    "for word, score in pairs:\n",
    "    if word not in ['королева_NOUN', 'король_NOUN', 'женщина_NOUN']:\n",
    "        print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мужчина_NOUN 0.6810498237609863\n"
     ]
    }
   ],
   "source": [
    "pairs = w2v_model.most_similar(positive=['королева_NOUN', 'женщина_NOUN'], negative=['король_NOUN'], topn=1)\n",
    "for word, score in pairs:\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "увеличение_NOUN 0.6744431853294373\n"
     ]
    }
   ],
   "source": [
    "pairs = w2v_model.most_similar(positive=['большой_ADJ', 'уменьшение_NOUN'], negative=['малый_ADJ'], topn=1)\n",
    "for word, score in pairs:\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лондон_PROPN 0.7275360822677612\n"
     ]
    }
   ],
   "source": [
    "vec = w2v_model['москва_PROPN'] - w2v_model['россия_PROPN'] + w2v_model['англия_PROPN']\n",
    "pairs = w2v_model.similar_by_vector(vec, topn=1, restrict_vocab=None)\n",
    "for word, score in pairs:\n",
    "        print(word, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](pic3.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Применение\n",
    "- Машинный перевод\n",
    "- Расширение поисковых запросов \n",
    "- Классификация текстов\n",
    "- Определение тональности высказываний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Интересные ссылки\n",
    "\n",
    "https://code.google.com/archive/p/word2vec/\n",
    "\n",
    "https://arxiv.org/pdf/1301.3781.pdf\n",
    "\n",
    "http://rusvectores.org/ru/\n",
    "\n",
    "https://youtu.be/U0LOSHY7U5Q\n",
    "\n",
    "https://youtu.be/2_mVrQ8fQro\n",
    "\n",
    "https://youtu.be/7k_MOBYbw_w\n",
    "\n",
    "https://habrahabr.ru/post/249215/\n",
    "\n",
    "https://habrahabr.ru/company/mlclass/blog/270591/\n",
    "\n",
    "https://habrahabr.ru/post/275913/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Спасибо за внимание!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "спаибо_NOUN 0.8570160865783691\n",
      "спасибище_NOUN 0.8269262313842773\n",
      "спасиб_NOUN 0.8243280649185181\n",
      "спасибок_NOUN 0.8180297017097473\n",
      "спосибо_NOUN 0.8178544044494629\n"
     ]
    }
   ],
   "source": [
    "pairs = w2v_model.most_similar(positive=['спасибо_NOUN'], topn=5)\n",
    "for word, score in pairs:\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
